{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "laa9tRjJ59bl"
   },
   "source": [
    "##### Copyright 2020 The TensorFlow Hub Authors.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2023-03-08T14:34:34.626025Z",
     "iopub.status.busy": "2023-03-08T14:34:34.625585Z",
     "iopub.status.idle": "2023-03-08T14:34:34.629160Z",
     "shell.execute_reply": "2023-03-08T14:34:34.628626Z"
    },
    "id": "T4ZHtBpK6Dom"
   },
   "outputs": [],
   "source": [
    "#@title Copyright 2020 The TensorFlow Hub Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hk5u_9KN1m-t"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/hub/tutorials/yamnet\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/yamnet.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/hub/blob/master/examples/colab/yamnet.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/hub/examples/colab/yamnet.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://tfhub.dev/google/yamnet/1\"><img src=\"https://www.tensorflow.org/images/hub_logo_32px.png\" />See TF Hub model</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2ep-q7k_5R-"
   },
   "source": [
    "# Sound classification with YAMNet\n",
    "\n",
    "YAMNet is a deep net that predicts 521 audio event [classes](https://github.com/tensorflow/models/blob/master/research/audioset/yamnet/yamnet_class_map.csv) from the [AudioSet-YouTube corpus](http://g.co/audioset) it was trained on. It employs the\n",
    "[Mobilenet_v1](https://arxiv.org/pdf/1704.04861.pdf) depthwise-separable\n",
    "convolution architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.13.0-cp311-cp311-macosx_12_0_arm64.whl (1.9 kB)\n",
      "Collecting tensorflow-macos==2.13.0\n",
      "  Using cached tensorflow_macos-2.13.0-cp311-cp311-macosx_12_0_arm64.whl (189.3 MB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=23.1.21\n",
      "  Using cached flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Using cached h5py-3.9.0-cp311-cp311-macosx_11_0_arm64.whl (2.6 MB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-16.0.0-py2.py3-none-macosx_11_0_arm64.whl (24.3 MB)\n",
      "Collecting numpy<=1.24.3,>=1.22\n",
      "  Using cached numpy-1.24.3-cp311-cp311-macosx_11_0_arm64.whl (13.8 MB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: packaging in ./env/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (23.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Using cached protobuf-4.23.4-cp37-abi3-macosx_10_9_universal2.whl (400 kB)\n",
      "Requirement already satisfied: setuptools in ./env/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (67.6.1)\n",
      "Requirement already satisfied: six>=1.12.0 in ./env/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6\n",
      "  Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Using cached wrapt-1.15.0-cp311-cp311-macosx_11_0_arm64.whl (36 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.56.0-cp311-cp311-macosx_10_10_universal2.whl (8.9 MB)\n",
      "Collecting tensorboard<2.14,>=2.13\n",
      "  Using cached tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0\n",
      "  Using cached tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "Collecting keras<2.14,>=2.13.1\n",
      "  Using cached keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "Collecting wheel<1.0,>=0.23.0\n",
      "  Using cached wheel-0.40.0-py3-none-any.whl (64 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.8/181.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Using cached tensorboard_data_server-0.7.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached Werkzeug-2.3.6-py3-none-any.whl (242 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting urllib3<2.0\n",
      "  Using cached urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.2.0-cp311-cp311-macosx_11_0_arm64.whl (122 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2023.5.7-py3-none-any.whl (156 kB)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Using cached MarkupSafe-2.1.3-cp311-cp311-macosx_10_9_universal2.whl (17 kB)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, wheel, urllib3, typing-extensions, termcolor, tensorflow-estimator, tensorboard-data-server, pyasn1, protobuf, oauthlib, numpy, MarkupSafe, markdown, keras, idna, grpcio, google-pasta, gast, charset-normalizer, certifi, cachetools, absl-py, werkzeug, rsa, requests, pyasn1-modules, opt-einsum, h5py, astunparse, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow-macos, tensorflow\n",
      "Successfully installed MarkupSafe-2.1.3 absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.1 certifi-2023.5.7 charset-normalizer-3.2.0 flatbuffers-23.5.26 gast-0.4.0 google-auth-2.22.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.56.0 h5py-3.9.0 idna-3.4 keras-2.13.1 libclang-16.0.0 markdown-3.4.3 numpy-1.24.3 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.23.4 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-2.31.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.13.0 tensorboard-data-server-0.7.1 tensorflow-2.13.0 tensorflow-estimator-2.13.0 tensorflow-macos-2.13.0 termcolor-2.3.0 typing-extensions-4.5.0 urllib3-1.26.16 werkzeug-2.3.6 wheel-0.40.0 wrapt-1.15.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting tensorflow-hub\n",
      "  Using cached tensorflow_hub-0.13.0-py2.py3-none-any.whl (100 kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in ./env/lib/python3.11/site-packages (from tensorflow-hub) (1.24.3)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in ./env/lib/python3.11/site-packages (from tensorflow-hub) (4.23.4)\n",
      "Installing collected packages: tensorflow-hub\n",
      "Successfully installed tensorflow-hub-0.13.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.7.2-cp311-cp311-macosx_11_0_arm64.whl (7.3 MB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.1.0-cp311-cp311-macosx_11_0_arm64.whl (229 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.41.0-cp311-cp311-macosx_10_9_universal2.whl (2.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.4-cp311-cp311-macosx_11_0_arm64.whl (63 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in ./env/lib/python3.11/site-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in ./env/lib/python3.11/site-packages (from matplotlib) (23.1)\n",
      "Collecting pillow>=6.2.0\n",
      "  Using cached Pillow-10.0.0-cp311-cp311-macosx_11_0_arm64.whl (3.1 MB)\n",
      "Collecting pyparsing<3.1,>=2.3.1\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./env/lib/python3.11/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in ./env/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.1.0 cycler-0.11.0 fonttools-4.41.0 kiwisolver-1.4.4 matplotlib-3.7.2 pillow-10.0.0 pyparsing-3.0.9\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.11.1-cp311-cp311-macosx_12_0_arm64.whl (29.5 MB)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in ./env/lib/python3.11/site-packages (from scipy) (1.24.3)\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.11.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install tensorflow-hub\n",
    "!pip install matplotlib\n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T14:34:34.632394Z",
     "iopub.status.busy": "2023-03-08T14:34:34.631926Z",
     "iopub.status.idle": "2023-03-08T14:34:37.201926Z",
     "shell.execute_reply": "2023-03-08T14:34:37.201217Z"
    },
    "id": "Bteu7pfkpt_f"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "from scipy.io import wavfile\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YSVs3zRrrYmY"
   },
   "source": [
    "Load the Model from TensorFlow Hub.\n",
    "\n",
    "Note: to read the documentation just follow the model's [url](https://tfhub.dev/google/yamnet/1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T14:34:37.206061Z",
     "iopub.status.busy": "2023-03-08T14:34:37.205240Z",
     "iopub.status.idle": "2023-03-08T14:34:44.567828Z",
     "shell.execute_reply": "2023-03-08T14:34:44.567113Z"
    },
    "id": "VX8Vzs6EpwMo"
   },
   "outputs": [],
   "source": [
    "# Load the model.\n",
    "model = hub.load('https://tfhub.dev/google/yamnet/1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lxWx6tOdtdBP"
   },
   "source": [
    "The labels file will be loaded from the models assets and is present at `model.class_map_path()`.\n",
    "You will load it on the `class_names` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T14:34:44.572061Z",
     "iopub.status.busy": "2023-03-08T14:34:44.571462Z",
     "iopub.status.idle": "2023-03-08T14:34:44.589989Z",
     "shell.execute_reply": "2023-03-08T14:34:44.589391Z"
    },
    "id": "EHSToAW--o4U"
   },
   "outputs": [],
   "source": [
    "# Find the name of the class with the top score when mean-aggregated across frames.\n",
    "def class_names_from_csv(class_map_csv_text):\n",
    "  \"\"\"Returns list of class names corresponding to score vector.\"\"\"\n",
    "  class_names = []\n",
    "  with tf.io.gfile.GFile(class_map_csv_text) as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "      class_names.append(row['display_name'])\n",
    "\n",
    "  return class_names\n",
    "\n",
    "class_map_path = model.class_map_path().numpy()\n",
    "class_names = class_names_from_csv(class_map_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mSFjRwkZ59lU"
   },
   "source": [
    "Add a method to verify and convert a loaded audio is on the proper sample_rate (16K), otherwise it would affect the model's results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T14:34:44.593304Z",
     "iopub.status.busy": "2023-03-08T14:34:44.592737Z",
     "iopub.status.idle": "2023-03-08T14:34:44.596637Z",
     "shell.execute_reply": "2023-03-08T14:34:44.596093Z"
    },
    "id": "LizGwWjc5w6A"
   },
   "outputs": [],
   "source": [
    "def ensure_sample_rate(original_sample_rate, waveform,\n",
    "                       desired_sample_rate=16000):\n",
    "  \"\"\"Resample waveform if required.\"\"\"\n",
    "  if original_sample_rate != desired_sample_rate:\n",
    "    desired_length = int(round(float(len(waveform)) /\n",
    "                               original_sample_rate * desired_sample_rate))\n",
    "    waveform = scipy.signal.resample(waveform, desired_length)\n",
    "  return desired_sample_rate, waveform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZEgCobA9bWl"
   },
   "source": [
    "## Downloading and preparing the sound file\n",
    "\n",
    "Here you will download a wav file and listen to it.\n",
    "If you have a file already available, just upload it to colab and use it instead.\n",
    "\n",
    "Note: The expected audio file should be a mono wav file at 16kHz sample rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T14:34:44.599601Z",
     "iopub.status.busy": "2023-03-08T14:34:44.599134Z",
     "iopub.status.idle": "2023-03-08T14:34:44.942794Z",
     "shell.execute_reply": "2023-03-08T14:34:44.941947Z"
    },
    "id": "WzZHvyTtsJrc"
   },
   "outputs": [],
   "source": [
    "!curl -O https://storage.googleapis.com/audioset/speech_whistling2.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T14:34:44.946928Z",
     "iopub.status.busy": "2023-03-08T14:34:44.946197Z",
     "iopub.status.idle": "2023-03-08T14:34:45.195299Z",
     "shell.execute_reply": "2023-03-08T14:34:45.194238Z"
    },
    "id": "D8LKmqvGzZzr"
   },
   "outputs": [],
   "source": [
    "!curl -O https://storage.googleapis.com/audioset/miaow_16k.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T14:34:45.199198Z",
     "iopub.status.busy": "2023-03-08T14:34:45.198498Z",
     "iopub.status.idle": "2023-03-08T14:34:45.217032Z",
     "shell.execute_reply": "2023-03-08T14:34:45.216489Z"
    },
    "id": "Wo9KJb-5zuz1"
   },
   "outputs": [],
   "source": [
    "# wav_file_name = 'speech_whistling2.wav'\n",
    "wav_file_name = '~/Downloads/piano_test.wav'\n",
    "sample_rate, wav_data = wavfile.read(wav_file_name, 'rb')\n",
    "sample_rate, wav_data = ensure_sample_rate(sample_rate, wav_data)\n",
    "\n",
    "# Show some basic information about the audio.\n",
    "duration = len(wav_data)/sample_rate\n",
    "print(f'Sample rate: {sample_rate} Hz')\n",
    "print(f'Total duration: {duration:.2f}s')\n",
    "print(f'Size of the input: {len(wav_data)}')\n",
    "print(wav_data.shape)\n",
    "print(wav_data[:10])\n",
    "\n",
    "# Convert wav_data to mono format.\n",
    "if len(wav_data.shape) == 2:\n",
    "    wav_data = np.mean(wav_data, axis=1).astype(np.int16)\n",
    "\n",
    "print(wav_data.shape)\n",
    "print(wav_data[:10])\n",
    "\n",
    "# Listening to the wav file.\n",
    "Audio(wav_data.T, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9I290COsMBm"
   },
   "source": [
    "The `wav_data` needs to be normalized to values in `[-1.0, 1.0]` (as stated in the model's [documentation](https://tfhub.dev/google/yamnet/1))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T14:34:45.222006Z",
     "iopub.status.busy": "2023-03-08T14:34:45.221431Z",
     "iopub.status.idle": "2023-03-08T14:34:45.224956Z",
     "shell.execute_reply": "2023-03-08T14:34:45.224366Z"
    },
    "id": "bKr78aCBsQo3"
   },
   "outputs": [],
   "source": [
    "waveform = wav_data / tf.int16.max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_Xwd4GPuMsB"
   },
   "source": [
    "## Executing the Model\n",
    "\n",
    "Now the easy part: using the data already prepared, you just call the model and get the: scores, embedding and the spectrogram.\n",
    "\n",
    "The score is the main result you will use.\n",
    "The spectrogram you will use to do some visualizations later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T14:34:45.228175Z",
     "iopub.status.busy": "2023-03-08T14:34:45.227632Z",
     "iopub.status.idle": "2023-03-08T14:34:46.857895Z",
     "shell.execute_reply": "2023-03-08T14:34:46.856953Z"
    },
    "id": "BJGP6r-At_Jc"
   },
   "outputs": [],
   "source": [
    "# Run the model, check the output.\n",
    "scores, embeddings, spectrogram = model(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T14:34:46.861355Z",
     "iopub.status.busy": "2023-03-08T14:34:46.860907Z",
     "iopub.status.idle": "2023-03-08T14:34:46.865597Z",
     "shell.execute_reply": "2023-03-08T14:34:46.865012Z"
    },
    "id": "Vmo7griQprDk"
   },
   "outputs": [],
   "source": [
    "scores_np = scores.numpy()\n",
    "spectrogram_np = spectrogram.numpy()\n",
    "infered_class = class_names[scores_np.mean(axis=0).argmax()]\n",
    "print(f'The main sound is: {infered_class}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uj2xLf-P_ndS"
   },
   "source": [
    "## Visualization\n",
    "\n",
    "YAMNet also returns some additional information that we can use for visualization.\n",
    "Let's take a look on the Waveform, spectrogram and the top classes inferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T14:34:46.868570Z",
     "iopub.status.busy": "2023-03-08T14:34:46.868347Z",
     "iopub.status.idle": "2023-03-08T14:34:47.504141Z",
     "shell.execute_reply": "2023-03-08T14:34:47.503455Z"
    },
    "id": "_QSTkmv7wr2M"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the waveform.\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(waveform)\n",
    "plt.xlim([0, len(waveform)])\n",
    "\n",
    "# Plot the log-mel spectrogram (returned by the model).\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.imshow(spectrogram_np.T, aspect='auto', interpolation='nearest', origin='lower')\n",
    "\n",
    "# Plot and label the model output scores for the top-scoring classes.\n",
    "mean_scores = np.mean(scores, axis=0)\n",
    "top_n = 10\n",
    "top_class_indices = np.argsort(mean_scores)[::-1][:top_n]\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.imshow(scores_np[:, top_class_indices].T, aspect='auto', interpolation='nearest', cmap='gray_r')\n",
    "\n",
    "# patch_padding = (PATCH_WINDOW_SECONDS / 2) / PATCH_HOP_SECONDS\n",
    "# values from the model documentation\n",
    "patch_padding = (0.025 / 2) / 0.01\n",
    "plt.xlim([-patch_padding-0.5, scores.shape[0] + patch_padding-0.5])\n",
    "# Label the top_N classes.\n",
    "yticks = range(0, top_n, 1)\n",
    "plt.yticks(yticks, [class_names[top_class_indices[x]] for x in yticks])\n",
    "_ = plt.ylim(-0.5 + np.array([top_n, 0]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "YAMNet.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
